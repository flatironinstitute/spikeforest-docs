{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assemble_website_data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "NrO0ybyxN4bC"
      },
      "cell_type": "markdown",
      "source": [
        "## Assemble website data\n",
        "\n",
        "This notebook assembles the data for the website.\n",
        "\n",
        "\n",
        "This is the info to Liz on 11/16/18:\n",
        "\n",
        "\n",
        "Here's the data for the website:\n",
        "```\n",
        "kb.loadObject(\n",
        "    key=dict(\n",
        "        target='spikeforest_website_dev',\n",
        "        name='studies'\n",
        "    )\n",
        ")\n",
        "\n",
        "kb.loadObject(\n",
        "    key=dict(\n",
        "        target='spikeforest_website_dev',\n",
        "        name='recordings'\n",
        "    )\n",
        ")\n",
        "\n",
        "kb.loadObject(\n",
        "    key=dict(\n",
        "        target='spikeforest_website_dev',\n",
        "        name='true_units'\n",
        "    )\n",
        ")\n",
        "\n",
        "kb.loadObject(\n",
        "    key=dict(\n",
        "        target='spikeforest_website_dev',\n",
        "        name='sorters'\n",
        "    )\n",
        ")\n",
        "```\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xcRxwVZ63fYn",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Only run this cell if you are running this on a hosted runtime that does not have these packages installed\n",
        "# Consider connecting to a local runtime\n",
        "%%capture\n",
        "!pip install spikeforest"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jHr10qe23rjS",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from kbucket import client as kb\n",
        "import spikeforest as sf\n",
        "import spikeextractors as si\n",
        "import json\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Rr17RFOw3uO-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Configure read/write access to kbucket\n",
        "sf.kbucketConfigRemote(name='spikeforest1-readwrite',ask_password=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2ZYwytf73wn8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "recording_collection_names=[\n",
        "    'spikeforest_magland_synth_recordings',\n",
        "    'spikeforest_bionet8c_recordings',\n",
        "    'spikeforest_bionet32c_recordings',\n",
        "    'spikeforest_mearec_tetrode_recordings'\n",
        "]\n",
        "\n",
        "batch_names=[\n",
        "    'summarize_recordings_magland_synth','summarize_recordings_bionet8c','summarize_recordings_bionet32c','summarize_recordings_mearec_tetrode',\n",
        "    'ms4_magland_synth','irc_magland_synth','sc_magland_synth',\n",
        "    'ms4_bionet8c','irc_bionet8c','sc_bionet8c',\n",
        "    'ms4_bionet32c','irc_bionet32c','sc_bionet32c',\n",
        "    'ms4_mearec_tetrode','irc_mearec_tetrode','sc_mearec_tetrode'\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rxNW9AU6rohW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Load the SpikeForest data\n",
        "SF=sf.SFData()\n",
        "for rcname in recording_collection_names:\n",
        "  print(rcname)\n",
        "  SF.loadRecordings(key=dict(name=rcname))\n",
        "for bname in batch_names:\n",
        "  print(bname)\n",
        "  SF.loadProcessingBatch(batch_name=bname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SHUYOM7N2eL9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def min_max_range(a):\n",
        "  return [min(a),max(a)]\n",
        "\n",
        "def compute_recording_ranges(study):\n",
        "  rnames=study.recordingNames()\n",
        "  summary_objects=[study.recording(rname).getSummaryObject() for rname in rnames]\n",
        "  recording_dirnames=[study.recording(rname).directory() for rname in rnames]\n",
        "  \n",
        "  duration_sec_list=[float(obj['computed_info']['duration_sec']) for obj in summary_objects]\n",
        "  num_channels_list=[int(obj['computed_info']['num_channels']) for obj in summary_objects]\n",
        "  samplerate_hz_list=[int(obj['computed_info']['samplerate']) for obj in summary_objects]\n",
        "  num_true_units_list=[int(len(study.recording(rname).trueUnitsInfo(format='json'))) for rname in rnames]\n",
        "  file_size_bytes_list=[int(kb.getFileSize(dirname+'/raw.mda')) for dirname in recording_dirnames]\n",
        "  \n",
        "  recording_ranges=dict(\n",
        "      duration_sec=min_max_range(duration_sec_list),\n",
        "      num_channels=min_max_range(num_channels_list),\n",
        "      samplerate_hz=min_max_range(samplerate_hz_list),\n",
        "      file_size_bytes=min_max_range(file_size_bytes_list),\n",
        "      num_ground_truth_units=min_max_range(num_true_units_list)\n",
        "  )\n",
        "  \n",
        "  return recording_ranges"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kNBjRKl0sTmj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Load the studies\n",
        "print('Loading studies')\n",
        "all_studies=[]\n",
        "studies_by_name=dict()\n",
        "for sname in SF.studyNames():\n",
        "  print(sname)\n",
        "  study=dict(name=sname)\n",
        "  study['sorters']=[] # initialize\n",
        "  study['num_recordings']=len(SF.study(sname).recordingNames())\n",
        "  study['recording_ranges']=compute_recording_ranges(SF.study(sname))\n",
        "  studies_by_name[sname]=study\n",
        "  all_studies.append(study)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zHRiNGaCslyq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Load the recordings\n",
        "print('Loading recordings')\n",
        "all_recordings=[]\n",
        "for sname in SF.studyNames():\n",
        "  SS=SF.study(sname)\n",
        "  for rname in SS.recordingNames():\n",
        "    RR=SS.recording(rname)\n",
        "    recording=RR.getObject()\n",
        "    all_recordings.append(recording)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u5NXFMRStXmW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Load the units\n",
        "all_true_units=[]\n",
        "unit_lookup=dict()\n",
        "for sname in SF.studyNames():\n",
        "  SS=SF.study(sname)\n",
        "  for rname in SS.recordingNames():\n",
        "    RR=SS.recording(rname)\n",
        "    true_units_info=RR.trueUnitsInfo(format='json')\n",
        "    for unit in true_units_info:\n",
        "      unit['study']=sname\n",
        "      unit['recording']=rname\n",
        "      unit['sorting_results']=dict()\n",
        "      all_true_units.append(unit)\n",
        "      code=sname+'---'+rname+'---'+str(unit['unit_id'])\n",
        "      unit_lookup[code]=unit\n",
        "print('Found {} true units'.format(len(all_true_units)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D70o3UnSuXsV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Load the sorting results\n",
        "print('Loading sorting results')\n",
        "count=0\n",
        "sorters_by_name=dict()\n",
        "for sname in SF.studyNames():\n",
        "  SS=SF.study(sname)\n",
        "  for rname in SS.recordingNames():\n",
        "    RR=SS.recording(rname)\n",
        "    for srname in RR.sortingResultNames():\n",
        "      SR=RR.sortingResult(srname)\n",
        "      result=SR.getObject()\n",
        "      if not SR.sorterName() in studies_by_name[sname]['sorters']:\n",
        "        studies_by_name[sname]['sorters'].append(SR.sorterName())\n",
        "      obj=SR.comparisonWithTruth(format='json')\n",
        "      sorter=dict(\n",
        "          name=result['sorter_name'],\n",
        "          processor_name=result['sorting_processor_name'],\n",
        "          processor_version=result['sorting_processor_version'],\n",
        "          params=result['sorting_params']\n",
        "      )\n",
        "      sorters_by_name[SR.sorterName()]=sorter\n",
        "      for unit_id in obj:\n",
        "        unit=obj[unit_id]\n",
        "        code=sname+'---'+rname+'---'+str(unit_id)\n",
        "        if code in unit_lookup:\n",
        "          unit_lookup[code]['sorting_results'][SR.sorterName()]=unit\n",
        "          count=count+1\n",
        "print('Loaded {} sorted units'.format(count))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zc7YqkZssRyG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "target='spikeforest_website_dev_12_18_2018'\n",
        "\n",
        "all_sorters=[]\n",
        "for sname in sorters_by_name:\n",
        "  all_sorters.append(sorters_by_name[sname])\n",
        "print('Found {} sorters'.format(len(all_sorters)))\n",
        "\n",
        "print('Saving {} studies'.format(len(all_studies)))\n",
        "kb.saveObject(\n",
        "    key=dict(\n",
        "        target=target,\n",
        "        name='studies'\n",
        "    ),\n",
        "    object=dict(\n",
        "        studies=all_studies\n",
        "    )\n",
        ")\n",
        "    \n",
        "print('Saving {} recordings'.format(len(all_recordings)))\n",
        "kb.saveObject(\n",
        "    key=dict(\n",
        "        target=target,\n",
        "        name='recordings'\n",
        "    ),\n",
        "    object=dict(\n",
        "        recordings=all_recordings\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "print('Saving {} true units'.format(len(all_true_units)))\n",
        "kb.saveObject(\n",
        "    key=dict(\n",
        "        target=target,\n",
        "        name='true_units'\n",
        "    ),\n",
        "    object=dict(\n",
        "        true_units=all_true_units\n",
        "    )\n",
        ")\n",
        "\n",
        "print('Saving {} sorters'.format(len(all_sorters)))\n",
        "kb.saveObject(\n",
        "    key=dict(\n",
        "        target=target,\n",
        "        name='sorters'\n",
        "    ),\n",
        "    object=dict(\n",
        "        sorters=all_sorters\n",
        "    )\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lkC4VTYTxJ5z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Study:')\n",
        "obj=kb.loadObject(\n",
        "    key=dict(\n",
        "        target='spikeforest_website_dev',\n",
        "        name='studies'\n",
        "    )\n",
        ")\n",
        "print(json.dumps(obj['studies'][0],indent=4))\n",
        "\n",
        "print('Recording:')\n",
        "obj=kb.loadObject(\n",
        "    key=dict(\n",
        "        target='spikeforest_website_dev',\n",
        "        name='recordings'\n",
        "    )\n",
        ")\n",
        "print(json.dumps(obj['recordings'][0],indent=4))\n",
        "\n",
        "\n",
        "print('Unit:')\n",
        "obj=kb.loadObject(\n",
        "    key=dict(\n",
        "        target='spikeforest_website_dev',\n",
        "        name='true_units'\n",
        "    )\n",
        ")\n",
        "print(json.dumps(obj['true_units'][0],indent=4))\n",
        "\n",
        "print('Sorter:')\n",
        "obj=kb.loadObject(\n",
        "    key=dict(\n",
        "        target='spikeforest_website_dev',\n",
        "        name='sorters'\n",
        "    )\n",
        ")\n",
        "print(json.dumps(obj['sorters'][0],indent=4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T_eSC6MnxR0E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('studies: '+kb.findFile(key=dict(\n",
        "    target='spikeforest_website_dev',\n",
        "    name='studies'\n",
        "),local=False,remote=True))\n",
        "\n",
        "print('recordings: '+kb.findFile(key=dict(\n",
        "    target='spikeforest_website_dev',\n",
        "    name='recordings'\n",
        "),local=False,remote=True))\n",
        "\n",
        "print('units: '+kb.findFile(key=dict(\n",
        "    target='spikeforest_website_dev',\n",
        "    name='true_units'\n",
        "),local=False,remote=True))\n",
        "\n",
        "print('sorters: '+kb.findFile(key=dict(\n",
        "    target='spikeforest_website_dev',\n",
        "    name='sorters'\n",
        "),local=False,remote=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "J-sXHMOjE2yF",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}